---
title: "News.bitcoin.com Web Scraping, Sentiment Classification Modeling, and Topic Modeling"
date: 2021-03-15
tags: [Python, Text Analysis]
excerpt: "Web scraping of articles, extraction of sentences, classification modeling, topic modeling."
mathjax: "true"

---
<img src="{{ site.url }}{{ site.baseurl }}/images/bitcoin.png" alt="Bitcoin logo">


# Overview
Tools utilized:
* Python


Python libraries used:
* [Pandas](https://pandas.pydata.org/docs/)
* [Sys](https://docs.python.org/3/library/sys.html)
* [NLTK](https://www.nltk.org/)
* [Textblob](https://textblob.readthedocs.io/en/dev/)
* [Sklearn](https://scikit-learn.org/stable/)
* OS
<br />
<br />


# Introduction
As part of a course-end project in my Text Analytics class, my group and I (colleagues Troy Parker and Praveen Gadkari), had to come up with a project that encapsulated everything we had learned over the semester.

The topics to be covered were as follows: Web scraping, sentiment classification, and cluster & topic analysis.

In choosing a topic to cover, the requirements were simple; there needed to be over 5,000 articles on the website, and the topic had to be timely and relevant. In 2021, cryptocurrencies have been making big headlines. Troy, a part-time scuba diving instructor, had just gotten back from an out-of-country diving trip where a self-made crypto millionare chartered him to instruct a private group of people.

## Methodology
### Site scraping
With our site selected, https://news.bitcoin.com/, 

### Normalization
Now that all of our data is standardized, normalizing the data will help us get more consistent results in our Machine Learning models.
Let's take a look at some box and whisker plots of our numeric features to see how they all compare to one another.
Using Seaborn and Matplotlib, the following code outputs a combined box and whisker plot of the standardized data.
```python
sns.set_palette('plasma')
sns.set_context('talk', font_scale = 0.75)
fig = standtracks[features_list].plot(kind = 'box', figsize = (20,10))
plt.savefig('Standardized.png')
```
<img src="{{ site.url }}{{ site.baseurl }}/images/SpotTrans/Standardized.png" alt="box and whisker before">

Next, to normalize each column, I created a normalization function that utilizes a simple normalization equation:
\\[ (X-Xmin)/(Xmax-Xmin)\\]
In the below function, it applies the above equation to columns that are not strings or are not our target variable, 'saved'.
```python
def normalize(df):
    result = df.copy()
    for col in df:
        if type(df[col][1]) != str and col != 'saved':
            max_val = df[col].max()
            min_val = df[col].min()
            result[col] = (df[col] - min_val) / (max_val - min_val)
            print(col, ' -- ', '*applied*')
        else:
            print(col, ' -- ', 'not applied')
            pass
    return result
```
When the standardized dataframe is passed to the function, it prints the column values and lets us know which columns were normalized, and which were not!
```python
proctracks = normalize(standtracks)
```
> artist  --  not applied <br />
> album  --  not applied <br />
> track_name  --  not applied <br />
> track_id  --  not applied <br />
> danceability  --  *applied* <br />
> energy  --  *applied* <br />
> key  --  *applied* <br />
> loudness  --  *applied* <br />
> mode  --  *applied* <br />
> speechiness  --  *applied* <br />
> instrumentalness  --  *applied* <br />
> liveness  --  *applied* <br />
> valence  --  *applied* <br />
> tempo  --  *applied* <br />
> duration_ms  --  *applied* <br />
> time_signature  --  *applied* <br />
> saved  --  not applied <br />

Using the below code, we are able to take a look at the box and whisker plots for the normalized and standardized dataset. Much better!
```python
sns.set_palette('plasma')
sns.set_context('talk', font_scale = 0.75)
fig = proctracks[features_list].plot(kind = 'box', figsize = (20,10))
plt.savefig('processed.png')
```
<img src="{{ site.url }}{{ site.baseurl }}/images/SpotTrans/processed.png" alt="box and whisker after">

# Output
It doesn't seem like we did a lot in this part, but the difference it will make in our machine learning models in Part 3 will be invaluable!
Our output from this section is a new data table, in the exact same format, with standardized and normalized values.

Take a look at my complete code [here](https://tyljporter.github.io/SpotifyP2/).
