---
title: "Spotify ML project: Part 1"
date: 2020-11-15
tags: [Python, API]
excerpt: "Extraction of Spotify user data for further analysis"
mathjax: "true"
---
# Introduction
As an avid music listener, after the discovery of the [Spotify API](https://developer.spotify.com/documentation/web-api/) and an accompanying [python library](https://spotipy.readthedocs.io/en/2.16.1/#), I was very excited to dig in and start playing with some of my own user data!

In my Spotify library, I have a master playlist of songs that fit into my favorite mash-up of genres: Post-harcore, pop punk, metalcore, and alt-rock; when I come across new music that fits into the genre, I throw it into that playlist so that I can come back to it later.
<div>
  <iframe src="https://open.spotify.com/embed/playlist/3dgfLqrR0v70pKNb961q6q" width="100%" height="350" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>
</div>


Spotify makes it easy to 'like' certain songs and places them in a separate, private playlist.
This got me thinking; assuming that all of my 'liked' songs are within the above playlist, can we use Machine Learning to decipher what makes a song go from simply a good song to one that I absolutely love?
<br />



# Overview
Tools utilized:
* Python
* Orange
* Spotify API


Python libraries used:
* [Spotipy](https://spotipy.readthedocs.io/en/2.16.1/#)
* [Pandas](https://pandas.pydata.org/docs/)
* [Sys](https://docs.python.org/3/library/sys.html)
* [Math](https://docs.python.org/3/library/math.html)
<br />



# Methodology

In order to get connected to the Spotify API, an app must be made within Spotify developer. This was easily done by following the instructions found in [Spotify's documentation](https://developer.spotify.com/documentation/web-api/quick-start/).

Once the application was created, a client ID and secret was generated. An easy to remember redirect URI was set.
(Note: These have been removed from the below code for security reasons)

In Python, these are set as local variables that are then passed to Spotipy's `prompt_for_user_token()` function that generates an authorization token that is then passed to authorization. This is also where the scope is set; for this project, all we will need is read only access to the user library. If the current user is not authorized, the code will prompt the user to login to Spotify, then paste the URL that the browser was redirected to.

```python
#Get token and authorize. Will prompt user to enter
#redirect URI on first run
username = ~~REDACTED~~
client_id = ~~REDACTED~~
client_secret = ~~REDACTED~~
redirect_uri = 'https://google.com/'
scope = 'user-library-read'

token = util.prompt_for_user_token(username=username,
                                   scope=scope,
                                   client_id=client_id,   
                                   client_secret=client_secret,     
                                   redirect_uri=redirect_uri)
sp = spotipy.Spotify(auth=token)
```


Now we are authorized and ready to start pulling some data!
The first step is to utilize Spotipy's `current_user_saved_tracks()` to pull my library of saved tracks. This defined function doesn't take any variables, but spotipy's function uses the username that is passed during the authentication process.
A custom function was created to return *all* saved tracks; Note: Spotipy returns paginated results with a 20 item limit. To learn more, click [here](https://spotipy.readthedocs.io/en/2.16.1/#spotipy.client.Spotify.current_user_saved_tracks).
```python
#Define function to pull saved tracks
def get_faves():
    results = sp.current_user_saved_tracks()
    tracks = results['items']
    while results['next']:
        results = sp.next(results)
        tracks.extend(results['items'])
    return tracks
```


Now that we have a function defined to collect my liked tracks, it's time to grab the contents of the 'poppostpunkcore' playlist.
Another custom function was created utilizing Spotipy's `user_playlist_tracks()` function. This function takes a single playlist ID that is obtained in Spotify.
<img src="{{ site.url }}{{ site.baseurl }}/images/SpotifyURI.jpg" alt="Get spotify platlist URI" width = "234" height = "287">

```python
def get_playlist_tracks(ID):
    sample = sp.user_playlist_tracks(username, ID)
    tracks = sample['items']
    while sample['next']:
        sample = sp.next(sample)
        tracks.extend(sample['items'])
    return tracks
```
Now both functions are ran and set to respective dataframes.
Spotipy returns nested JSON for both functions, as demonstrated below:
```python
#URI of larger playlist
#Pull both sets of tracks, then demonstrate output.
ID = 'spotify:playlist:3dgfLqrR0v70pKNb961q6q'
faves = get_faves()
playlist = get_playlist_tracks(ID)
faves[1]

{'added_at': '2020-11-12T17:17:48Z',
 'track': {'album': {'album_type': 'album',
   'artists': [{'external_urls': {'spotify': 'https://open.spotify.com/artist/6guC9FqvlVboSKTI77NG2k'},
     'href': 'https://api.spotify.com/v1/artists/6guC9FqvlVboSKTI77NG2k',
     'id': '6guC9FqvlVboSKTI77NG2k',
     'name': 'Dance Gavin Dance',
     'type': 'artist',
     'uri': 'spotify:artist:6guC9FqvlVboSKTI77NG2k'}],
   'available_markets': ['AD',
    'AE',
    'AL',
    'AR',
    'AT',
    'AU',
    'BA',
    'BE',
    ...
```

In order to analyze the songs within these datasets, a custom function was created that takes 'tracks' as an input, and outputs audio features in a Pandas dataframe using the `audio_features()` function in the Spotipy library.
```python
def analyze(tracks):
    #Initialize features to be added
    features_list = ['artist','album','track_name','track_id',
                     'danceability','energy','key','loudness',
                     'mode', 'speechiness','instrumentalness',
                     'liveness','valence','tempo', 'duration_ms',
                     'time_signature']
    df = pd.DataFrame(columns = features_list)
    # Loop through every track in the playlist, pull metadata and audio features using spotipy and append to df
    for track in tracks:
        # Create empty dict
        features = {}
        # Get metadata
        features['artist'] = track['track']['album']['artists'][0]['name']
        features['album'] = track['track']['album']['name']
        features['track_name'] = track['track']['name']
        features['track_id'] = track['track']['id']

        # Get audio features
        audio_features = sp.audio_features(features['track_id'])[0]
        for feature in features_list[4:]:
            features[feature] = audio_features[feature]

        # Concat the dfs
        track_df = pd.DataFrame(features, index = [0])
        df = pd.concat([df, track_df], ignore_index = True)
    return df
```

First, the 'faves' json object is passed through the function. Once it is output, a target variable, `saved`, is set to 1. This will be the target variable for future machine learning objectives.
```python
#analyze tracks JSON
tracks = analyze(faves)
#Set target variable of saved songs to '1'
tracks['saved'] = '1'
```

Second, the 'poppostpunkcore' playlist is passed through the function, and the target variable is set to 0.
```python
#Analyze larger playlist tracks
playlist = analyze(playlist)
#Set target variable of suggested songs to '0'
playlist['saved'] = '0'
```

The results are then appended, with the index ignored.
```python
#Append larger sample to other df
tracks = tracks.append(playlist, ignore_index = True)
```

Since some of the tracks in the 'liked' category are contained in the 'poppostpunkcore' playlist, duplicates are dropped with the second occurance to be deleted; this ensures that the values with 1 as the target variable remain.
```python
#Now have list of faves, sample of larger set with some faves in it. Need to remove duplicates,
#Leaving the first instance
tracks = tracks.drop_duplicates(subset = 'track_id', keep = 'first')
```
<br />



# Output
Utilizing Panda's `.to_csv()` function, a .csv file is output, with the index ignored.
```python
tracks.to_csv('tracks.csv', index = False)
```
The resulting .csv file is as follows:
<table class="table table-bordered table-hover table-condensed">
<thead><tr><th title="Field #1">artist</th>
<th title="Field #2">album</th>
<th title="Field #3">track_name</th>
<th title="Field #4">track_id</th>
<th title="Field #5">danceability</th>
<th title="Field #6">energy</th>
<th title="Field #7">key</th>
<th title="Field #8">loudness</th>
<th title="Field #9">mode</th>
<th title="Field #10">speechiness</th>
<th title="Field #11">instrumentalness</th>
<th title="Field #12">liveness</th>
<th title="Field #13">valence</th>
<th title="Field #14">tempo</th>
<th title="Field #15">duration_ms</th>
<th title="Field #16">time_signature</th>
<th title="Field #17">saved</th>
</tr></thead>
<tbody
<tr>
<td>Dance Gavin Dance</td>
<td>Instant Gratification</td>
<td>Death Of A Strawberry</td>
<td>0ZcQUwVyXgpUepJsvgOYgk</td>
<td align="right">0.576</td>
<td align="right">0.955</td>
<td align="right">4</td>
<td align="right">-3.122</td>
<td>1</td>
<td align="right">0.0458</td>
<td align="right">0.0</td>
<td align="right">0.054</td>
<td align="right">0.752</td>
<td align="right">124.972</td>
<td align="right">250973</td>
<td align="right">4</td>
<td>1</td>
</tr>
<tr>
<td>Youth Fountain</td>
<td>Letters to Our Former Selves</td>
<td>Rose Coloured Glass</td>
<td>5W1hGiWjGuQHoqd30nUkZR</td>
<td align="right">0.389</td>
<td align="right">0.984</td>
<td align="right">0</td>
<td align="right">-3.159</td>
<td>0</td>
<td align="right">0.235</td>
<td align="right">0.000187</td>
<td align="right">0.34</td>
<td align="right">0.617</td>
<td align="right">190.055</td>
<td align="right">197250</td>
<td align="right">4</td>
<td>0</td>
</tr>
</tbody></table>
